Progetto Advanced Analytics | start2impact University
Questo repository contiene il notebook del progetto sviluppato nell'ambito del Corso Advanced Analytics di start2impact University. Il progetto esplora diverse tecniche di analisi dei dati e di machine learning, spaziando dalla regressione alla classificazione, fino all'apprendimento non supervisionato e all'analisi delle serie temporali.
üìö Librerie Principali Utilizzate
Il progetto fa uso delle seguenti librerie Python, essenziali per la manipolazione dei dati, l'analisi statistica, la visualizzazione e la costruzione di modelli di Machine Learning:
‚Ä¢ numpy per operazioni numeriche e calcoli statistici.
‚Ä¢ pandas per la manipolazione e l'analisi dei dati tabellari.
‚Ä¢ scipy (in particolare scipy.stats) per calcoli statistici come la moda e la skewness.
‚Ä¢ matplotlib.pyplot per la visualizzazione dei dati.
‚Ä¢ google.colab.drive per l'accesso a Google Drive (se il notebook viene eseguito su Google Colab).
‚Ä¢ sklearn.preprocessing (LabelEncoder, StandardScaler, PolynomialFeatures) per la pre-elaborazione dei dati e la creazione di feature polinomiali.
‚Ä¢ sklearn.model_selection (train_test_split) per la suddivisione del dataset in set di training e test.
‚Ä¢ sklearn.linear_model (LinearRegression, LogisticRegression) per l'implementazione dei modelli di regressione lineare e logistica.
‚Ä¢ sklearn.metrics (mean_squared_error, mean_absolute_error, r2_score, classification_report, f1_score, confusion_matrix) per la valutazione delle performance dei modelli.
‚Ä¢ sklearn.tree (DecisionTreeClassifier) per l'implementazione del modello ad albero decisionale.
‚Ä¢ sklearn.cluster (KMeans) per l'implementazione dell'algoritmo di clustering K-Means.
‚Ä¢ seaborn per la visualizzazione avanzata (es. heatmap per la confusion matrix).
üìä Esplorazione del Dataset e Pre-elaborazione (Supermarket Sales)
Il primo dataset utilizzato √® supermarket_sales.csv, che contiene dati sulle vendite di un supermercato.
1. Caricamento e Ispezione Iniziale: Il dataset viene caricato e le prime 100 occorrenze vengono visualizzate per una comprensione intuitiva dei dati.
2. Metadati e Pulizia:
    ‚ó¶ Viene ispezionato il tipo di dato e l'assenza di valori nulli.
    ‚ó¶ Colonne ritenute poco utili per l'analisi predittiva, come 'Invoice ID', 'Tax 5%', 'Total', 'Date', 'Time', 'cogs', 'gross margin percentage', vengono rimosse.
üìà Analisi Statistica Descrittiva
Per la colonna Rating, che √® la variabile target (label) per la predizione, sono state calcolate le seguenti statistiche:
‚Ä¢ Media del Rating: 6.78.
‚Ä¢ Mediana del Rating: 6.8.
‚Ä¢ Moda del Rating: Modalit√†(5.9) Frequenza(73).
‚Ä¢ Deviazione Standard del Rating: 1.72.
La distribuzione dei rating √® risultata essere pi√π o meno uniforme e senza skewness.
In contrasto, la colonna gross income (utile lordo) mostra una significativa skewness, con la maggioranza degli ordini che presentano un basso reddito lordo. Il valore esatto della skewness per gross income √® 0.95.
üõ†Ô∏è Feature Engineering
Per preparare i dati ai modelli di machine learning, sono state applicate le seguenti tecniche:
1. Encoding delle Variabili Categoriche: Colonne come 'Branch', 'City', 'Customer type', 'Gender', 'Product line' e 'Payment' sono state trasformate da categoriche a numeriche utilizzando LabelEncoder. Questo √® fondamentale poich√© gli algoritmi di machine learning richiedono input numerici.
    ‚ó¶ Viene mostrata la mappatura dei valori originali ai valori codificati per ciascuna colonna.
2. Feature Scaling (Standardizzazione): Le colonne 'Unit price' e 'gross income' sono state standardizzate utilizzando StandardScaler. Questa operazione aiuta a migliorare le performance dei modelli, specialmente per 'gross income' che presentava una forte skewness. La standardizzazione viene verificata controllando che la media delle colonne sia prossima a 0 e la deviazione standard a 1.
üß™ Training e Valutazione dei Modelli di Regressione
Il dataset pre-processato viene diviso in set di training (80%) e test (20%) per la valutazione dei modelli di regressione, con Rating come variabile target.
1. Regressione Lineare
‚Ä¢ Un modello di LinearRegression √® stato addestrato per predire i Rating.
‚Ä¢ Metriche di Valutazione:
    ‚ó¶ Mean Squared Error (MSE): 2.97.
    ‚ó¶ Mean Absolute Error (MAE): 1.35.
    ‚ó¶ R2-score: -0.0003.
‚Ä¢ Conclusione: L'R2-score estremamente basso indica che il modello lineare √® peggiore rispetto a una semplice media dei valori, suggerendo che un modello lineare non cattura adeguatamente la relazione nei dati.
2. Regressione Polinomiale
‚Ä¢ √à stata tentata una PolynomialRegression per migliorare le performance, inizialmente con un grado del polinomio pari a 2.
‚Ä¢ Metriche di Valutazione (Grado 2):
    ‚ó¶ MSE: 2.99.
    ‚ó¶ MAE: 1.36.
    ‚ó¶ R2-score: -0.0080.
‚Ä¢ Conclusione (Grado 2): Le performance sono peggiorate rispetto alla regressione lineare semplice.
‚Ä¢ Esperimenti con Gradi Maggiori: Sono stati testati gradi del polinomio da 3 a 5.
    ‚ó¶ Grado 3: MSE = 3.01, MAE = 1.37, R2 = -0.0093.
    ‚ó¶ Grado 4: MSE = 3.03, MAE = 1.37, R2 = -0.0175.
    ‚ó¶ Grado 5: MSE = 3.03, MAE = 1.37, R2 = -0.0175.
‚Ä¢ Spiegazione del Peggioramento: L'aumento del grado del polinomio non ha portato a miglioramenti, anzi, le performance sono peggiorate. Questo suggerisce che la causa potrebbe essere l'overfitting dei dati, probabilmente dovuto a un dataset dimensionalmente limitato (con pochi dati), il che comporta una ridotta capacit√† di generalizzazione del modello. Non sono stati riscontrati outlier significativi che possano giustificare il peggioramento delle performance.
üçé Classificazione della Qualit√† delle Mele
Per un problema di classificazione, √® stato introdotto un nuovo dataset: apple_quality.csv. L'obiettivo √® classificare la qualit√† delle mele.
1. Caricamento e Pulizia: Il dataset viene caricato. Viene rimossa l'ultima riga, che presentava valori nulli.
2. Encoding della Label: La colonna 'Quality', che √® la label categorica, viene encodata numericamente utilizzando LabelEncoder ('Good' e 'Bad' vengono mappate).
3. Train/Test Split: Il dataset viene nuovamente diviso in training (80%) e test (20%).
1. Regressione Logistica
‚Ä¢ Un modello LogisticRegression √® stato addestrato per la classificazione della qualit√† delle mele.
‚Ä¢ Metrica Iniziale (F1-score): L'obiettivo √® superare un F1-score di 0.80, massimizzando precision e recall.
‚Ä¢ Ottimizzazione del Threshold: √à stato cercato il miglior threshold per la probabilit√† di predizione (predict_proba) per massimizzare l'F1-score.
    ‚ó¶ Miglior Threshold Trovato: 0.49.
    ‚ó¶ Miglior F1-score (media ponderata): 0.80.
    ‚ó¶ Analisi delle Metriche dopo Thresholding: Si √® notato che l'F1-score sulla label '1' (qualit√† buona) migliora a scapito dell'altra label, mentre le medie 'macro avg' e 'weighted avg' per F1-score e recall rimangono invariate. La precision migliora sulla label '2' a discapito dell'altra, e le medie 'macro avg' e 'weighted avg' per la precision migliorano.
‚Ä¢ Confusion Matrix (Regressione Logistica):
    ‚ó¶ Visualizzata per comprendere le performance del modello.
    ‚ó¶ Esempio di valori estratti: TP = 100, TN = 100, FP = 0, FN = 0 (questi sono valori specifici estratti dalla matrice, che possono variare in base all'esecuzione).
    ‚ó¶ Ratio True/False: Il rapporto tra predizioni corrette (True) e predizioni errate (False) √® stato calcolato come 67% (dato da (True Positives + True Negatives) / Totale).
2. Decision Tree
‚Ä¢ Un modello DecisionTreeClassifier √® stato addestrato per la classificazione della qualit√† delle mele.
‚Ä¢ Analisi dei Criteri di Suddivisione (criterion): Sono stati testati i criteri 'gini' ed 'entropy' per la suddivisione dei rami.
    ‚ó¶ Conclusione: Nel caso specifico, il criterio entropy ha offerto le migliori performance.
‚Ä¢ Confusion Matrix (Decision Tree):
    ‚ó¶ Visualizzata per comprendere le performance.
    ‚ó¶ Conclusione sul Confronto: Con il Decision Tree, ci sono stati meno errori rispetto alla Logistic Regression, e il rapporto tra predizioni corrette e errate √® risultato maggiore (71% vs 67%), indicando una migliore performance.
‚Ä¢ Feature Importance: Sono state calcolate e stampate le importanze delle feature, indicando quali caratteristiche delle mele sono state pi√π rilevanti per il modello Decision Tree nella classificazione.
üß© K-Means Clustering
Questa sezione esplora l'algoritmo di clustering non supervisionato K-Means.
1. Preparazione del Dataset: La label 'Quality' viene rimossa dal dataset classification_dataset per creare clustering_dataset, poich√© K-Means non utilizza la label.
2. Clustering con n_clusters=2:
    ‚ó¶ Il modello KMeans √® stato addestrato con due cluster, assumendo che le mele siano "buone" o "cattive".
    ‚ó¶ Vengono visualizzati i centroidi dei cluster.
    ‚ó¶ Una nuova colonna 'Cluster' viene aggiunta al dataset, indicando a quale cluster √® stata assegnata ciascuna mela.
    ‚ó¶ √à possibile effettuare una predizione per una mela specifica (data in input tramite ID), che indicher√† se √® "buona" o "cattiva".
3. Clustering con n_clusters=3:
    ‚ó¶ Viene esplorato lo scenario con tre cluster per verificare la possibilit√† di una qualit√† intermedia.
    ‚ó¶ Il modello KMeans viene addestrato con tre cluster.
    ‚ó¶ Vengono visualizzati i centroidi dei cluster.
    ‚ó¶ Anche qui, una nuova colonna 'Cluster' viene aggiunta.
    ‚ó¶ Effettuando una predizione, il modello pu√≤ ora classificare una mela come "buona", "cattiva" o "di qualit√† intermedia".
‚è≥ Analisi delle Serie Temporali
L'ultima parte del progetto si concentra sulle serie temporali, utilizzando nuovamente il dataset originale regression_raw_dataset. L'obiettivo √® analizzare come il gross income evolve nel tempo.
1. Creazione del Dataset Time Series: Viene creato un nuovo dataset, timeseries_dataset, contenente solo le colonne 'Date' e 'gross income'.
2. Regressione Lineare su Serie Temporali:
    ‚ó¶ La colonna 'Date' viene convertita in formato datetime e suddivisa in feature numeriche 'Day', 'Month', 'Year' per essere utilizzata nel modello.
    ‚ó¶ Il dataset viene diviso in training (80%) e test (20%).
    ‚ó¶ Un modello LinearRegression viene addestrato sulla serie temporale.
    ‚ó¶ Metriche di Valutazione:
        ‚ñ™ Mean Squared Error (MSE): 55.77.
        ‚ñ™ Mean Absolute Error (MAE): 5.58.
    ‚ó¶ Conclusione: I valori di MSE e MAE, sebbene possano sembrare non elevati, indicano che la regressione lineare spesso fallisce sulle serie temporali, suggerendo la necessit√† di modelli pi√π performanti (come gli algoritmi specifici per serie temporali).
